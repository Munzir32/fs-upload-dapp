"use client";

import { useQuery } from "@tanstack/react-query";
import { EnhancedDataSetInfo, PDPServer } from "@filoz/synapse-sdk";
import { useAccount } from "wagmi";
import { DataSet } from "@/types";
import { useSynapse } from "@/providers/SynapseProvider";
import { getDatasetsSizeInfo } from "@/utils/calculateStorageMetrics";

/**
 * Hook to fetch and manage user datasets from Filecoin storage
 *
 * @description This hook demonstrates a complex data fetching workflow:
 * 1. Initialize Synapse and WarmStorage services
 * 2. Fetch approved providers and user datasets in parallel
 * 3. Map provider relationships and fetch provider details
 * 4. Enrich datasets with provider information and PDP data
 * 5. Handle errors gracefully while maintaining data integrity
 * 6. Implement caching and background refresh strategies
 *
 * @returns React Query result containing enriched datasets with provider info
 *
 * @example
 * const { data, isLoading, error } = useDatasets();
 *
 * if (data?.datasets?.length > 0) {
 *   const firstPieceCid = data.datasets[0]?.data?.pieces[0]?.pieceCid;
 *   console.log('Flag (First Piece CID):', firstPieceCid);
 * }
 */
export const useDatasets = () => {
  const { address } = useAccount();
  const { synapse } = useSynapse();

  return useQuery({
    enabled: !!address,
    queryKey: ["datasets", address],
    queryFn: async () => {
      // STEP 1: Validate prerequisites
      if (!synapse) throw new Error("Synapse not found");

      // STEP 3: Fetch providers and datasets in parallel for efficiency
      const datasets = await synapse.storage.findDataSets();

      // STEP 5: Fetch provider information with error handling
      const datasetsSizeInfo = await getDatasetsSizeInfo(datasets, synapse);
      console.log("datasetsSizeInfo", datasetsSizeInfo);
      const providers = await Promise.all(
        datasets.map((dataset) => synapse.getProviderInfo(dataset.providerId))
      );

      // STEP 6: Create provider ID to service URL mapping
      const providerIdToServiceUrlMap = providers.reduce((acc, provider) => {
        acc[provider.id] = provider.products.PDP?.data.serviceURL || "";
        return acc;
      }, {} as Record<string, string>);

      // STEP 7: Fetch detailed dataset information with PDP data
      const datasetDataResults = await Promise.all(
        datasets.map(async (dataset: EnhancedDataSetInfo) => {
          const serviceURL = providerIdToServiceUrlMap[dataset.providerId];
          const provider = providers.find((p) => p.id === dataset.providerId);

          try {
            // Connect to PDP server to get piece information
            const pdpServer = new PDPServer(null, serviceURL || "");
            const data = await pdpServer.getDataSet(
              dataset.pdpVerifierDataSetId
            );

            return {
              ...dataset,
              provider: provider,
              serviceURL: serviceURL,
              data, // Contains pieces array with CIDs
              ...datasetsSizeInfo[dataset.pdpVerifierDataSetId],
            } as DataSet;
          } catch (error) {
            console.warn(
              `Failed to fetch dataset details for ${dataset.pdpVerifierDataSetId}:`,
              error
            );
            // Return dataset without detailed data but preserve basic info
            return {
              ...dataset,
              provider: provider,
              serviceURL: serviceURL,
              message: "datasetsSizeInfo[dataset.pdpVerifierDataSetId].message",
            } as unknown as DataSet;
          }
        })
      );

      // STEP 9: Map results back to original dataset order
      const datasetsWithDetails = datasets.map((dataset) => {
        const dataResult = datasetDataResults.find(
          (result) =>
            result.pdpVerifierDataSetId === dataset.pdpVerifierDataSetId
        );
        return dataResult;
      });

      return { datasets: datasetsWithDetails };
    },
  });
};
